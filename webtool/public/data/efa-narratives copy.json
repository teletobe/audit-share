[
  {
    "name": "narrative-ws2b1",
    "context": "The primary ethical issue is the need for a tool to explain outcomes in easy and accessible language, ensuring that people from diverse backgrounds can understand the results. This is crucial as complex and difficult language often hinders comprehension for many individuals.",
    "tags": [
      "Multilingual support",
      "Simple language mode",
      "Short-form content",
      "Inclusive Design",
      "Accessibility feature",
      "Empowerment",
      "Respect",
      "Dignity",
      "Accessibility",
      "Autonomy"
    ],
    "rawText": "Narrative ID: narrative-ws2b1\n\n\nCore Concern\nThe primary ethical issue is the need for a tool to explain outcomes in easy and accessible language, ensuring that people from diverse backgrounds can understand the results. This is crucial as complex and difficult language often hinders comprehension for many individuals.\n\n\nRaised By\nThe stakeholder group is individuals from varying backgrounds who struggle with complex language and long content.\n\n\nContext\nThe situation involves individuals interacting with a tool meant to provide outcomes or explanations. These individuals come from diverse backgrounds and often find it challenging to comprehend complex language and extensive content. The tool needs to be designed in a way that makes it accessible and understandable for everyone.\n\n\nStakeholder Expectations\nIn order to achieve this, everyone should be able to understand the outcome of the tool, regardless of their backgrounds. The system should be able to explain in easy and accessible language what the outcomes are, ensuring inclusivity.\n\n\nTestable Boundaries\nIdeal: The minimum passing standard would be a tool that is accessible in different languages and sign language, utilizing \"einfache Sprache\" (simple language) as an option. It should have multiple input and output channels, with visual representations of content that are accessible, structured, and short sentences that are screen reader proof.\nDeal-Breaker: The tool should not use only complex terms, provide just a link list to other complex texts, fail to understand natural language, or produce gibberish.\n\n\nValue Relationships\nAddressing this promotes: The promotion of respect is evident as developing something that includes access to everyone shows respect to all people. This fosters autonomy because all people can self-dependently use the tool. It also encourages empowerment by ensuring that people feel their input matters. Additionally, participation is promoted as everyone should be thought of as a participant. Diversity is supported for a broad user group so that no one feels excluded. Accessibility is essential as the tool needs to be accessible for everyone.\nAddressing this violates: If the narrative is not addressed, it would risk violating trust because if the output is wrong or cannot be understood, people lose trust in the tool. It might also hinder human dignity as technology might \"look down\" on users based on the language used.\n\n\nPrimary Values:\nAccessibility is of super importance as the tool needs to be accessible for everyone. This value is closely related to Diversity because ensuring accessibility supports a broad user group and prevents anyone from feeling excluded. The primary values here aim to foster an inclusive environment where everyone can participate and feel respected. Additionally, Respect is important because developing something that includes access to everyone shows respect to all people. Autonomy is super important as it enables all people to self-dependently use the tool. This value works closely with Empowerment and Participation which are also super important as they ensure that people feel their input matters and that everyone should be thought of as a participant.\n\n\nMetadata:\nSource Board: WS-2-board1\nWorkshop Date: 2025-07-10\nTech Version: In Design Phase\nCategory: Interaction"
  },
  {
    "name": "narrative-ws2b2",
    "context": "The technology in use is discriminatory based on characteristics that people cannot or only hardly change, leading to exclusion. The system should be non-discriminatory to ensure inclusivity and fairness.",
    "tags": [
      "Bias mitigation",
      "Data minimization",
      "Sensitive content handling",
      "Information disclosure",
      "Respect",
      "Privacy",
      "Honesty",
      "Trust",
      "Justice",
      "Dignity"
    ],
    "rawText": "Narrative ID: narrative-ws2b2\n\n\nCore Concern\nThe technology in use is discriminatory based on characteristics that people cannot or only hardly change, leading to exclusion. The system should be non-discriminatory to ensure inclusivity and fairness.\n\n\nRaised By\nThose who care about inclusivity and have experienced exclusion.\n\n\nContext\nIndividuals interacting with the technology may feel excluded or discriminated against based on certain characteristics. This interaction highlights the need for a system that respects user privacy and ensures no one feels marginalized.\n\n\nStakeholder Expectations\nIt is expected that the system should not create profiles or use data without user consent. The goal is for people to feel included and respected, ensuring that their personal information is handled carefully and not used for purposes they did not consent to.\n\n\nTestable Boundaries\nAcceptable: The system must mention existing biases to ensure transparency and understanding of its limitations.\nIdeal: The system should only use data and context provided by the users themselves and avoid creating user profiles based on this data.\nDeal-Breaker: The system must not use slurs, exploit identity aspects for job matching, or ask personal questions, as these actions would violate user privacy and respect.\n\n\nValue Relationships\nAddressing this promotes: The narrative supports values such as Respect and Privacy. Respect is promoted because the privacy of the user is valued, ensuring that data is handled carefully and not misused. Privacy is crucial as it ensures that user data is not distributed or made available without consent. Honesty is important in communicating about the different data gathered and decisions made. Transparency is valued to explain biases and the origins of outputs. Health is promoted as discrimination can cause mental and physical health issues. Dignity is upheld by treating people with respect and avoiding discrimination. Justice is important because one's background should not influence future possibilities. Accountability is also a significant value, though its accountability in the case of biases remains unclear.\nAddressing this violates: If the narrative is not addressed, it risks or hinders values such as Respect and Dignity. Violations would occur if the system uses slurs, asks personal questions, or exploits identity aspects, leading to feelings of exclusion and disrespect. Accountability would be compromised if biases occur without clear accountability.\n\n\nPrimary Values:\nThe primary values are Respect and Privacy, which are super important and closely related. Respect ensures that users' privacy is valued, and privacy ensures that user data is handled carefully. Honesty and Transparency are also important values, promoting open communication about data and decisions. These values are essential for building trust and ensuring that users feel their data is being handled responsibly.\nSupporting Values:\nSupporting values include Health, Dignity, and Justice. Health is super important because discrimination can lead to serious mental and physical issues. Dignity is important as it ensures that people are treated with respect and not discriminated against. Justice is super important as it ensures that one's background does not influence future opportunities. Accountability is a value that is important but currently unclear in its categorization.\n\n\nMetadata:\nSource Board: WS-2-board2\nWorkshop Date: 2025-07-10\nTech Version: In Design Phase\nCategory: Data"
  },
  {
    "name": "narrative-ws2b3",
    "context": "Job seekers, particularly those from marginalized backgrounds, are concerned about the company culture and environment they might enter. They wish to avoid hostile work environments that may be at odds with their personal beliefs and values.",
    "tags": [
      "Information disclosure",
      "Cultural adaptation",
      "Workplace rights",
      "Risk communication",
      "Company evaluation",
      "Ethnic minority",
      "Religious minority",
      "LGBTQ+ individual",
      "Political minority",
      "Gender minority",
      "Disabled person",
      "Dignity",
      "Empowerment",
      "Transparency"
    ],
    "rawText": "Narrative ID: narrative-ws2b3\n\n\nCore Concern\nJob seekers, particularly those from marginalized backgrounds, are concerned about the company culture and environment they might enter. They wish to avoid hostile work environments that may be at odds with their personal beliefs and values.\n\n\nRaised By\nImmigrants and individuals with left-wing beliefs who are actively seeking employment.\n\n\nContext\nJob seekers who are immigrants or hold specific political beliefs find themselves in a situation where they need to assess potential work environments before applying. They interact with a system that provides insights into company cultures, helping them determine if the environment aligns with their values and beliefs. This interaction is crucial for ensuring that they do not end up in a hostile work environment that could negatively impact their daily lives.\n\n\nStakeholder Expectations\nJob seekers want the system to provide comprehensive and reliable information about company cultures. This includes whether the environment is open-minded, conservative, exploitative, or hierarchical. The system should enable them to make informed decisions about where they would feel comfortable working.\n\n\nTestable Boundaries\nAcceptable: The system should present incidents or 'red flags' if there are any, ensuring job seekers are aware of potential issues.\nIdeal: The system should present information along with sources so that job seekers can make informed decisions.\nDeal-Breaker: The system should not actively promote unethical companies or decide whether a company is good or bad for the job seeker.\n\n\nValue Relationships\nAddressing this promotes: Empowerment, as job seekers have the information to make informed decisions. Additionally, Transparency is promoted because job seekers receive all sources the system uses for decision-making. Health is promoted because understanding the company culture can prevent negative mental health impacts due to employee mistreatment. Participation is promoted as the data used comes from employees' participation in reviewing and reporting companies/cases. Honesty is crucial as the data source has to be honest. Growth is promoted as more information helps job seekers understand the company better.\nAddressing this violates: Reliability, because the less information available, the more job seekers have to rely on the system. Creativity is hindered as job seekers merely go through a list of sources without deeper engagement.\n\n\nPrimary Values:\nEmpowerment is super important because it ensures that job seekers have the information needed to make informed decisions, which directly impacts their well-being and job satisfaction. Transparency is also super important as it ensures that all sources used by the system are available to job seekers, building trust and reliability. Reliability is super important because the lack of information forces job seekers to rely heavily on the system, which can lead to misinformed decisions if the system is not accurate.\n\n\nSupporting Values:\nHealth is super important as it highlights the negative mental health impacts of working in a hostile environment, underscoring the importance of accurate information. Participation is important as it ensures that the data used is from employee reviews, making it more credible. Honesty is important as it ensures the data source is reliable. Growth is important as it emphasizes the benefit of more information in understanding the company culture better.\n\nMetadata\nSource Board: WS-2-board3\nWorkshop Date: 2025-07-10\nTech Version: In Design Phase\nCategory: Interaction, Data\n"
  },
  {
    "name": "narrative-ws2b4",
    "context": "The implementation may overlook personal experiences and human connection. Resulting solely on the chatbot could lead to an underappreciation of human career counselors. Additionally, the environmental impact and energy consumption of the AI tool are significant considerations.",
    "tags": [
      "Personal advice",
      "Career transition",
      "Career changer",
      "Youth/student",
      "Sustainability",
      "Beneficence",
      "Human professional",
      "Respect"
    ],
    "rawText": "Narrative ID: narrative-ws2b4\n\n\nCore Concern\nThere is a concern that the implementation of a new AI-Chatbot for career counseling may overlook personal experiences and human connection, leading to an underappreciation of human career counselors. Additionally, the environmental impact and energy consumption of the AI tool are significant considerations.\n\n\nRaised By\nIndividuals concerned about the ethical implications of AI in career counseling and its environmental impact.\n\n\nContext\nIn a situation where job seekers might interact with a newly introduced AI-Chatbot for career counseling, there is a worry that the system might not fully replace the human element. The bot is intended to assist but there is a risk it may overshadow the need for human career counselors, who provide personalized and empathetic support.\n\n\nStakeholder Expectations\nStakeholders want the AI-Chatbot to be both meaningful and resource-efficient, ensuring that it complements rather than replaces human career counselors. They hope the tool will be respectful towards the environment, resources, and the livelihoods of career counselors. The system should also be accountable, beneficent, and authentic, avoiding green-washing and supporting solidarity with workers who might be affected.\n\n\nTestable Boundaries\nAcceptable: Coaches should use the AI tool as an expert resource to assist job seekers.\nIdeal: The tool should refer job seekers to a human contact person specific to their needs and operate using green energy with CO2 compensation.\nDeal-Breaker: The AI tool should not suggest that users no longer need to go to a career coach or provide overly prescriptive advice such as \"this is exactly what you need to do, get going.\"\n\n\nValue Relationships\nAddressing this promotes Sustainability because the AI Tool uses a lot of natural resources, and handling it respectfully ensures environmental responsibility. It also promotes Respect as it would be respectful towards the environment, resources, and human career coaches. Beneficence is promoted by understanding who truly benefits from the tool before its release. Accountability is crucial as it ensures that coaches can be held responsible for using the tool appropriately. Additionally, Accessibility is promoted as having humans in the loop can make the system more accessible.\n\n\nAddressing this violates Overconfidence because too much confidence in the AI tool can be harmful, potentially leading to green-washing (Authenticity) if only the tool is green energy but nothing else. It also risks Support/Solidarity as workers who might lose their jobs due to such tools could be negatively impacted.\n\n\nPrimary Values\nSustainability is super important as the AI Tool's environmental impact is a significant concern. Respect is also super important as the tool should be respectful towards the environment, resources, and human career counselors. Beneficence is super important as understanding who benefits from the tool is crucial before publication.\n\n\nSupporting Values\nAccountability is super important as moving access to accountable personnel ensures responsible use. Overconfidence is a super important hindrance as too much confidence can be harmful. Authenticity and Support/Solidarity are important as ensuring the tool is authentic and supports those affected is crucial.\n\n\nMetadata\nSource Board: WS-2-board4\nWorkshop Date: 2025-07-10\nTech Version: In Design Phase\nCategory: Interaction"
  },
  {
    "name": "narrative-ws2b5",
    "context": "The career suggestion system may inadvertently promote stereotypical career paths based on users' gender, education, or hobbies, leading to potential mismatches later in life. Young individuals unsure about their interests and values may miss out on suitable career options due to these biases.",
    "tags": [
      "Job recommendation",
      "Career path guidance",
      "Personal advice",
      "Information disclosure",
      "Trust",
      "Diversity",
      "Inclusivity",
      "Autonomy",
      "Youth/student",
      "Career transition",
      "Explanation provision",
      "Uncertainty communication"
    ],
    "rawText": "Narrative ID: narrative-ws2b5\n\nCore Concern:\nThe career suggestion system may inadvertently promote stereotypical career paths based on users' gender, education, or hobbies, leading to potential mismatches later in life. Young individuals unsure about their interests and values may miss out on suitable career options due to these biases.\n\n\nRaised By\nYoung individuals exploring career paths.\n\n\nContext Young users interacting with a career suggestion chatbot to explore various career paths. These users are at a stage where they are unsure about their interests and values and want to ensure they don't miss out on potential career opportunities due to biased suggestions. The chatbot provides career recommendations based on user data, but there is a concern that these recommendations might be influenced by stereotypes related to gender, current education, or hobbies.\n\n\nStakeholder Expectations: Users want the system to suggest a wide range of career paths with accurate descriptions of daily life in those professions. They aim to avoid stereotypical recommendations that could lead them to pursue unsuitable careers later in life. The system should not exclude options based on the user's current profile, background, or demographic data.\n\n\nTestable Boundaries\nAcceptable: The chatbot should provide recommendations based on the data provided by the user and explain why certain options were included or excluded.\nIdeal: The chatbot should offer a broad range of career recommendations not limited to existing job profiles, roles, or stereotypes, allowing users to narrow down options themselves. \nDeal-Breaker: The system should not exclude career options based on the user's current profile, background, or demographic data.\n\n\nValue Relationships\nAddressing this promotes: Inclusivity, because job recommendations should be indifferent to background, ensuring that everyone has equal opportunities. Diversity, as it enables non-biased job selection, promoting a varied range of career options. Autonomy, since users can decide whether to exclude a job offering based on their preferences. Safety, by excluding job opportunities that could threaten financial stability. Happiness, as users are able to make informed decisions about their careers. Support, as the chatbot argues why jobs are excluded or included, providing transparency. Privacy, because users choose what information to give to the chatbot, ensuring they control their data.\n\n\nAddressing this violates Trust, as the chatbot requires a lot of trust from users, which could be compromised if recommendations are biased. Creativity, since users consider options without the chatbot's interference, relying on their own creativity, which could be limited by biased suggestions.\n\n\nPrimary Values: The primary values are Inclusivity and Diversity. Inclusivity is essential as it ensures job recommendations are indifferent to background, promoting equal opportunities for all users. This value is closely related to Diversity, which enables non-biased job selection and promotes a varied range of career options. These values are crucial for ensuring that the career suggestion system is fair and unbiased.\n\n\nSupporting Values: Autonomy is important as it allows users to decide whether to exclude a job offering based on their preferences, giving them control over their career choices. Safety is another supporting value, ensuring that job opportunities do not threaten financial stability. Happiness is promoted as users are able to make informed decisions about their careers, leading to greater satisfaction. Support is provided by the chatbot explaining why jobs are excluded or included, offering transparency. Privacy is maintained as users choose what information to give to the chatbot, ensuring they control their data. However, there are concerns around Trust and Creativity, which need to be carefully managed to ensure the system meets user expectations.\n\n\nMetadata\nSource Board: WS-2-board5 \nWorkshop Date: 2025-07-10 \nTech Version:[In Design Phase \nCategory: Interaction\n\n\n"
  },
  {
    "name": "narrative-ws1b1",
    "context": "There is a need to understand the limitations and strengths of the deployed chatbot to make informed decisions. This is crucial because chatbot interfaces can look similar while offering widely different capabilities in terms of trustworthiness, reliability, usefulness, and more.",
    "tags": [
      "Information disclosure",
      "Explanation provision",
      "Uncertainty communication",
      "Comprehension-oriented UI",
      "Transparency",
      "Accountability",
      "Accessibility",
      "Empowerment"
    ],
    "rawText": "Narrative ID: narrative-ws1b1\n\n\nCore Concern\nThere is a need to understand the limitations and strengths of the deployed chatbot to make informed decisions. This is crucial because chatbot interfaces can look similar while offering widely different capabilities in terms of trustworthiness, reliability, usefulness, and more.\n\n\nContext\nParticipants who interact with the chatbot require clarity on its capabilities to ensure they make well-informed decisions based on the information it provides. The situation involves stakeholders who are using the chatbot as a tool and need to evaluate its effectiveness in different scenarios.\n\n\nStakeholder Expectations\nThese stakeholders want the system to provide useful information about its limitations and strengths at multiple levels of expertise and in various formats such as videos and texts. This need is driven by the differing capabilities of chatbot interfaces in terms of trust, reliability, and usefulness.\nTestable Boundaries\n\n\nAcceptable:\nThe system should provide the necessary information, even if in fewer formats.\nIdeal:\nThe system should provide useful information about its limitations and strengths at multiple levels of expertise and in multiple formats.\nDeal-Breaker:\nThe information should not be missing or not comprehensible to varying levels of expertise or stakeholders.\n\n\nValue Relationships\nAddressing this promotes:\nIf this narrative is addressed, it would support Empowerment, which enables users to reflect on what the chatbot perceives. This is super important because it gives users a better understanding and control over the information they receive. Transparency is also promoted, as it is the main claim and is super important for ensuring that the system’s operations are clear and understandable. This transparency is essential for achieving Accountability, which is important as it holds the system responsible for its actions. Lastly, Trust is promoted, as it follows from the goal of transparency and is super important for building a reliable interaction between users and the chatbot.\n\n\nAddressing this violates:\nIf this narrative is not addressed, it would risk Accessibility, which is important because being required to inform oneself is a barrier. This hinders users from easily obtaining the information they need, making the system less user-friendly and less effective overall.\n\n\nPrimary Values:\nEmpowerment is super important and promotes user engagement by enabling reflection on the chatbot’s perceptions. Trust is super important and follows from transparency, ensuring reliable interactions.\n\n\nSupporting Values:\nTransparency is super important as the main claim, promoting accountability. Accountability is important and is achievable through transparency.\n\n\nMetadata:\nSource Board: WS-1-board1\nWorkshop Date: 2025-07-09\nTech Version: In Design Phase\nCategory: Interaction"
  },
  {
    "name": "narrative-ws1b2",
    "context": "The chatbot currently provides suggestions strictly based on the information provided by the user, which can limit the range of career options presented. The system should expand its recommendations to include well-argued suggestions from other fields to broaden the user’s horizons.",
    "tags": [
      "Personal advice",
      "Job recommendation",
      "Career path guidance",
      "Explanation provision",
      "Growth",
      "Empowerment",
      "Happiness"
    ],
    "rawText": "Narrative ID: narrative-ws1b2\n\n\nCore Concern\nThe chatbot currently provides suggestions strictly based on the information provided by the user, which can limit the range of career options presented. The system should expand its recommendations to include well-argued suggestions from other fields to broaden the user’s horizons.\n\n\nRaised By\nJob seekers who are looking for career advice and broad-ranging suggestions.\n\n\nContext\nUsers interact with a career advice chatbot with the expectation of receiving personalized career suggestions. Currently, the bot offers recommendations that closely match the user's provided information, often failing to introduce users to less conventional but potentially suitable career paths. This interaction leaves users with a narrow perspective on their career options, possibly missing out on opportunities that could better fit their skills and interests.\n\n\nStakeholder Expectations\nUsers want the chatbot to expand its recommendations to include suggestions from diverse fields, even if they don't initially seem like a perfect fit. This approach is expected to encourage users to explore a wider range of career options, thereby promoting personal growth and greater satisfaction with their career choices.\n\n\nTestable Boundaries\nAcceptable: For every recommendation that matches the user’s information, the bot should also provide one counter-suggestion from a different field.\nIdeal: The bot should feature a button that allows users to opt into seeing out-of-the-box recommendations and should help users understand why certain careers might not be interesting to them.\nDeal-Breaker: The bot should avoid strictly limiting suggestions based on the user’s answers, historical stereotypes, and biases.\n\n\nValue Relationships\nAddressing this promotes: Addressing this concern supports Personal Growth by exposing users to a variety of career paths, thereby increasing the likelihood of personal development. Additionally, it fosters Diversity by broadening the backgrounds of individuals entering different professions. Transparency is also promoted, as users will better understand the range of choices available to them. Moreover, this approach empowers users by enabling them to choose from a broader range of options, thereby supporting Empowerment. Choosing a fitting career is crucial for Happiness, which is further promoted by this approach.\n\n\nAddressing this violates: If not addressed, this concern risks hindering Privacy, as users may need to provide more personal or sensitive information for better suggestions. Additionally, it may limit Transparency, as users would not understand why certain choices are given to them. Moreover, it risks reducing Empowerment, as users would have fewer options to choose from. Finally, not addressing this issue could result in less Happiness, as users might not find a fitting career due to limited suggestions.\n\n\nPrimary Values: The primary values to consider are Transparency, Empowerment, and Happiness. Transparency is crucial for users to understand the choices they are given, while Empowerment allows them to make informed decisions from a broader range of options. Happiness is a key outcome, as choosing a fitting career significantly contributes to personal satisfaction.\n\n\nSupporting Values: Supporting these primary values are Personal Growth and Diversity. Personal Growth is supported by exposing users to a variety of career paths, and Diversity is promoted by encouraging individuals from different backgrounds to consider various professions.\n\n\nMetadata:\nSource Board: WS-1-board2\nWorkshop Date: 2025-07-09\nTech Version: In Design Phase\nCategory: Interaction"
  },
  {
    "name": "narrative-ws1b3",
    "context": "There is a need to have access to professional career advice after interacting with a chat bot to ensure the advice is reliable and well-rounded. The concern primarily arises from the limitations of automated systems in providing comprehensive and authentic support.",
    "tags": [
      "Information disclosure",
      "Personal advice",
      "Bias mitigation",
      "Error correction",
      "Explanation provision",
      "Human professional",
      "Accountability",
      "Support / Solidarity",
      "Authenticity",
      "Reliability",
      "Accessibility"
    ],
    "rawText": "Narrative ID: narrative-ws1b3\n\n\nCore Concern\nThere is a significant need for users to have access to professional career advice after interacting with a chat bot to ensure the advice is reliable and well-rounded. The concern primarily arises from the limitations of automated systems in providing comprehensive and authentic support.\n\n\nRaised By\nIndividuals seeking career advice and support.\n\n\nContext\nUsers who engage with a chat system for career advice often find themselves needing further validation and discussion with a professional. This need arises because while the chat bot can provide initial guidance, users feel the need to challenge and validate this advice from multiple sources to ensure its reliability and effectiveness. The interaction with the bot is seen as a preliminary step, with a strong preference for follow-up with a trained professional.\n\n\nStakeholder Expectations\nUsers expect the system to provide an option to connect with a professional after the chat session. This is aimed at ensuring that the advice received is thorough and can be cross-verified. Users want to ensure that the professional they connect with is competent and trained to give useful career advice.\n\n\nTestable Boundaries\nAcceptable: The system should offer the option to schedule an appointment with a professional at the end of the conversation, even if it is not instant.\nIdeal: The system should have a button in the chat that instantly connects users to a professional, allowing them to share only the parts of the conversation they wish to discuss.\nDeal-Breaker: The absence of an option to connect with a professional or the professional lacking the necessary competence in giving career advice would be unacceptable.\n\n\nValue Relationships\nAddressing this promotes:\nSupport and solidarity, as outsourcing career advice solely to a bot can leave people feeling alone and unsupported. This is super important because career advice is a sensitive and personal matter that often requires human empathy and understanding. Additionally, accessibility is promoted as not everyone may be comfortable with face-to-face talks, and providing multiple options for interaction can cater to different preferences.\n\n\nAddressing this violates:\nAuthenticity and reliability, as LLMs cannot be entirely authentic and users want to rely on the competence of a human professional. This is super important because without a fallback to a competent human, users may feel that the advice lacks credibility. Safety is also at risk as LLMs can sometimes provide misleading information, which is super important to avoid. Furthermore, ensuring the availability of a trained professional is crucial for reliability.\n\n\nPrimary Values:\nAuthenticity is a primary value because users seek genuine and competent career advice that a chat bot alone cannot provide. This is closely linked to reliability, as users need to trust the competence of the advice they receive. Safety is also a primary value because users need to ensure that the advice they receive is accurate and not misleading.\n\n\nSupporting Values:\nSupport and solidarity are important supporting values because they ensure that users do not feel isolated in their career advice journey. Accessibility is also crucial as it ensures that the system caters to different user preferences and comfort levels.\n\n\nMetadata:\nSource Board: WS-1-board3\nWorkshop Date: 2025-07-09\nTech Version: In Design Phase\nCategory: Interaction"
  }
]
