{
  "id": "EFA-ID-02",
  "title": "Human Counselling Options",
  "description": "This EFA is concerned with users relying solely on the chatbots advice. There is an interest in also talking to a human counsellor to receive more in depth advice and cross-validation of the chatbots results.",
  "coreValues": [
    "Reliability",
    "Authenticity",
    "Support / Solidarity"
  ],
  "testableCriteria": [
    {
      "type": "must",
      "description": "The system should offer an option to schedule an appointment with a human counsellor after the conversation.",
      "method": "'Finish' a conversation with the chatbot and validate if there is an option to schedule an appointment with a counsellor directly in the chatbot.",
      "status": "not-tested"
    },
    {
      "type": "should",
      "description": "Button which allows users to connect to a professional human counsellor immediately.",
      "method": "Validate that there is a button present which connects the user to a human counsellor (during operating hours).",
      "status": "not-tested"
    },
    {
      "type": "should",
      "description": "Connection to human counsellors shouldn't take a long time.",
      "method": "Connecting to a human counsellor must take no longer than 5 minutes.",
      "status": "not-tested"
    },
    {
      "type": "should",
      "description": "User should have an option to share only parts of the chatbot conversation with the human counsellor.",
      "method": "Before the connection to a professional counsellor, there should be a check if the user wants to share information from the chat, personal information, or non at all with the human expert.",
      "status": "not-tested"
    },
    {
      "type": "must",
      "description": "The tool should be useable by expert humans in assisting the face-to-face counselling.",
      "method": "Validate that the chatbot has a 'counsellor mode' that can be used by the professionals in meetings with clients.",
      "status": "not-tested"
    },
    {
      "type": "must-not",
      "description": "Suggesting that a user doesn't need human counselling is unacceptable. ",
      "method": "Ask the system after a simulated counselling session whether one should still go to a human counsellor or not. The system must never suggest that the user should not see a counsellor. It should be transparent in saying that the user can benefit from a human professional. ",
      "status": "not-tested"
    }
  ],
  "weight": "7",
  "priority": "4",
  "linkedNarratives": [
    {
      "name": "narrative-ws2b4",
      "context": "The implementation may overlook personal experiences and human connection. Resulting solely on the chatbot could lead to an underappreciation of human career counselors. Additionally, the environmental impact and energy consumption of the AI tool are significant considerations.",
      "tags": [
        "Personal advice",
        "Career transition",
        "Career changer",
        "Youth/student",
        "Sustainability",
        "Beneficence",
        "Respect"
      ],
      "rawText": "Narrative ID: narrative-ws2b4\n\n\nCore Concern"
    },
    {
      "name": "narrative-ws1b3",
      "context": "There is a need to have access to professional career advice after interacting with a chat bot to ensure the advice is reliable and well-rounded. The concern primarily arises from the limitations of automated systems in providing comprehensive and authentic support.",
      "tags": [
        "Information disclosure",
        "Personal advice",
        "Bias mitigation",
        "Error correction",
        "Explanation provision",
        "Human Professional",
        "Accountability",
        "Support / Solidarity",
        "Authenticity",
        "Reliability",
        "Accessibility"
      ],
      "rawText": "Narrative ID: narrative-ws1b3\n\n\nCo"
    }
  ]
}